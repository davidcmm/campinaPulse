---
title: "Pairwise comparison - logit"
#date: `r date()`
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
require(gmodels)
require(vcd)
require(lme4)
library(nlme)
library(caret)
library(pscl)
library(DT)
library(ggplot2)
theme_set(theme_bw())
library(GGally)
library(dplyr, warn.conflicts = F)
library(broom)

library(car)
library(readr)
```

```{r lib}
#tasks finished by each user
teste <- read.table("classifier//classifier_input_wodraw.dat", sep="\t", header=TRUE)

teste_seg <- filter(teste, question == "seguro" | question == "seguro?")
teste_agrad <- filter(teste, !(question == "seguro" | question == "seguro?"))

processTasks <- function (teste, usersFile, top10File){
  ids <- unique(teste$userID)
  tasks <- c()
  for (id in ids){
    tasks <- append(tasks, nrow(filter(teste, userID == id)))
  }
  userTasks <- data.frame(userID=ids, tasks=tasks)
  for(id in arrange(userTasks, -tasks)$userID[1:10]){
    t1 <- as.data.frame(table(unlist(filter(teste, userID == id)$photo1)))
    t2 <- as.data.frame(table(unlist(filter(teste, userID == id)$photo2)))
    
    merged <- merge(t1, t2, by="Var1")
    merged$total <- merged$Freq.x + merged$Freq.y
    
    sink(top10File, append=TRUE)
    print(paste(">>> ID ", id))
    sink()
    write.table(merged, file=top10File, quote = FALSE, row.names = FALSE, append = TRUE)
  }
  write.table(arrange(userTasks, -tasks), file=usersFile, quote = FALSE, row.names = FALSE)
}

#Pleasantness tasks
processTasks(teste_agrad, "users_tasks_agrad.dat", "top10_users_agrad.dat")

#Safety tasks
processTasks(teste_seg, "users_tasks_seg.dat", "top10_users_seg.dat")

#Lendo qscores para top usuarios
for (file in list.files("predictions/", pattern="all_predicted_.*") ){
  print(file)
  top <- read.table(paste("predictions/", file, sep=""))
  #top <- read.table("predictions/all_predicted_seg_adu.dat")
  novoV2 <- lapply(as.character(top$V2), function (x) paste(strsplit(x, split="/", fixed=TRUE)[[1]][6], "/", strsplit(x, split="/", fixed=TRUE)[[1]][7], sep=""))
  local <- unlist(lapply(novoV2, '[[', 1))
  top$V2 <- local
  
  if(grepl("agra", file)){
    top_quest <- filter(filter(top, V1 == "agrad%C3%A1vel?"), V3 > 0)#Fotos nao avaliadas tem QScore -1
    general = agrad.l
  }else{
    top_quest <- filter(filter(top, V1 == "seguro?"), V3 > 0)#Fotos nao avaliadas tem QScore -1
    general = seg.l
  }
  
  merged <- NULL
  if(grepl("masc", file)){
      merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Masculino), by.x ="V2", by.y="image_url")
      merged <- arrange(merged, V3.Masculino) %>% mutate(rank = 1:n())
  } else if (grepl("fem", file)){
      merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Feminino), by.x ="V2", by.y="image_url")
      merged <- arrange(merged, V3.Feminino) %>% mutate(rank = 1:n())
  } else if (grepl("adu", file)){
      merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Adulto), by.x ="V2", by.y="image_url")
      merged <- arrange(merged, V3.Adulto) %>% mutate(rank = 1:n())
  } else if (grepl("jov", file)){
      merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Jovem), by.x ="V2", by.y="image_url")
      merged <- arrange(merged, V3.Jovem) %>% mutate(rank = 1:n())
  } else if (grepl("bai", file)){
      merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Baixa), by.x ="V2", by.y="image_url")
      merged <- arrange(merged, V3.Baixa) %>% mutate(rank = 1:n())
  } else if (grepl("med", file)) {
    merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Media), by.x ="V2", by.y="image_url")
    merged <- arrange(merged, V3.Media) %>% mutate(rank = 1:n())
  } else{
    merged <- merge(select(top_quest, V1, V2, V3), select(general, V1, image_url, V3.Geral), by.x ="V2", by.y="image_url")
    merged <- arrange(merged, V3.Geral) %>% mutate(rank = 1:n())
  }
  
  merged <- arrange(merged, V3) %>% mutate(index = 1:n())
  result <- cor.test(merged$rank, merged$index, method="kendall")
  print(result)
  normalizedKendallTauDistance2(merged$rank, merged$index)
}
```


```{r lib}
compare_glms <- function(baseline, model){
  modelChi <- baseline$deviance - model$deviance
  chidf <- baseline$df.residual - model$df.residual
  chisq.prob <- 1 - pchisq(modelChi, chidf)
  print(paste(modelChi, chidf, chisq.prob))
}

compare_null <- function(baselineModel){
  modelChi <- baselineModel$null.deviance - baselineModel$deviance
  chidf <- baselineModel$df.null - baselineModel$df.residual
  chisq.prob <- 1 - pchisq(modelChi, chidf)
  print(paste(modelChi, chidf, chisq.prob))
}
```


```{r read}
# TIVE QUE ADICIONAR O NOME DA 1a COLUNA NO ARQUIVO
raw_data = read_delim(
  "classifier//classifier_input_wodraw.dat",
  delim = "\t",
  col_types = cols(
    .default = col_double(),
    row = col_integer(),
    choice = col_character(),
    question = col_character(),
    photo1 = col_character(),
    photo2 = col_character(),
    choice = col_integer(),
    userID = col_integer(),
    gender = col_character(),
    age = col_character(),
    income = col_character(),
    education = col_character(),
    city = col_character(),
    marital = col_character(),
    graffiti1 = col_character(),
    bairro1 = col_character(),
    graffiti2 = col_character(),
    bairro2 = col_character()
    )
  )

```

```{r transform}
data = raw_data %>% 
  mutate( # Recode
    income = if_else(is.na(income), "media", income),
    age_cat = if_else(as.integer(age) >= 25 | is.na(age), "adulto", "jovem"),
    inc_cat = if_else(income %in% c("baixa", "media baixa"),
                         "baixa", 
                         "media"), # substituirÃ¡ os NA
    choice = if_else(choice == "1", "0", 
                       if_else(choice == "-1", "1", choice)), 
    bair_cat = if_else(bairro1 == bairro2, "mesmo", 
                       paste0(bairro1, "_", bairro2))    
    ) %>% 
  mutate_at( # to factor
    vars(income, age_cat, inc_cat, choice, bair_cat, marital, gender),
    as.factor) %>% 
  mutate( # relevel
    bair_cat = relevel(bair_cat,  "mesmo"),
    marital = relevel(marital,  "solteiro"),
    income = relevel(income,  "baixa"),
    age_cat = relevel(age_cat,  "jovem"),
    gender = relevel(gender,  "feminino"),
    inc_cat = relevel(inc_cat,  "baixa")
  ) 

# Create diff features
data = data %>%
  mutate(
    d_swidth = street_wid1 - street_wid2,
    d_mvcars = mov_cars1 - mov_cars2,
    d_pcars = park_cars1 - park_cars2,
    d_trees = trees1 - trees2,
    d_mvciclyst = mov_ciclyst1 - mov_ciclyst2,
    d_lands = landscape1 - landscape2,
    d_bid = build_ident1 - build_ident2,
    d_bheig = log2(build_height1 + 1) - log2(build_height2 + 1),
    d_dbuild = diff_build1 - diff_build2,
    d_people = people1 - people2,
    d_graff = (graffiti1 == "Yes") - (graffiti2 == "Yes")
  )

#Creating file to be used with classify.py pairwise prediction
write.table(file = "classifier/input_to_classifier_predictions.dat", x = select(data, userID, photo1, photo2, question, choice, d_swidth, d_mvcars, d_pcars, d_trees, d_mvciclyst, d_lands, d_bid, d_bheig, d_dbuild, d_people, d_graff, bair_cat, gender, age_cat, inc_cat),quote = FALSE, sep = "\t", row.names = FALSE, col.names = TRUE)

# SPLIT + SCALE
agrad_scaled <- filter(data, !(question %in% c("seguro?", "seguro"))) %>% 
  mutate_at(vars(40:50), scale)
agrad_nscaled <- filter(data, !(question %in% c("seguro?", "seguro")))
seg_scaled <- filter(data, (question %in% c("seguro?", "seguro")))  %>% 
  mutate_at(vars(40:50), scale)
seg_nscaled <- filter(data, (question %in% c("seguro?", "seguro")))
```

```{r visualize}
 # featurePlot(x=data[, 40:45], y=data[,5], plot="box", scales=list(x=list(relation="free"), y=list(relation="free")), auto.key=list(columns=2))
```

```{r model.lib}
create_model_only_int = function(the_data){
  return(glm(
    choice ~ 1,
    data = the_data,
    family = binomial())) 
  #gls(choice ~ 1, data = agrad, method = "ML")
}

create_model_only_int_random = function(the_data){
  return( glmer(choice ~ 1 + (1|userID), data = the_data, family=binomial()) )
  #lme(as.integer(choice) ~ 1, data = agrad, random = ~1|userID, method="ML")
}

#Logistic regressions assumptions: http://www.statisticssolutions.com/assumptions-of-logistic-regression/
create_model_w_interact = function(the_data){
  return(glm(
    choice ~ d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff + bair_cat + 
      age_cat:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) + 
      gender:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) + 
      inc_cat:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff),
    data = the_data,
    family = binomial()))
}

create_model_wo_profile = function(the_data){
  return(glm(
    choice ~ d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff + bair_cat,
    data = the_data,
    family = binomial()))
}

#Random effects links: https://onlinecourses.science.psu.edu/stat502/node/171 (concepts, use); http://ase.tufts.edu/gsc/gradresources/guidetomixedmodelsinr/mixed%20model%20guide.html (how to specify in r); http://web.pdx.edu/~newsomj/mlrclass/ho_randfixd.pdf (variables, effects); http://liberalarts.utexas.edu/prc/_files/cs/Spring2013_Sasson_Fixed%20and%20Random%20Effects.pdf (examples of models formulas)
#- Extrapolar conclusoes alem dos dados que se tem; Dados desbalanceados em categorias; Foco na variancia e nao nas medias!

create_random_model_w_interact = function(the_data, optimizer_to_use=""){
  if ( nchar(optimizer_to_use) == 0 ){
    return( glmer( choice ~ d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff + bair_cat +
            age_cat:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) +
            gender:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) +
            inc_cat:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) + (1|userID), data = the_data, family=binomial() ) )
    
  }else{
    return( glmer( choice ~ d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff + bair_cat +
            age_cat:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) +
            gender:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) +
            inc_cat:(d_swidth + d_mvcars + d_pcars + d_trees + d_mvciclyst + d_lands + d_bid + d_bheig + d_dbuild + d_people + d_graff) + (1|userID), data = the_data, family=binomial(), control = glmerControl(optimizer=c(optimizer_to_use) ) ) )#optimizers="bobyqa", "Nelder_Mead"
  }
}

```

# Logit analysis with random effects
```{r model.agrad}
computePseudoR2 <- function(baselineModel, completeModel){
  print("Hosmer and Lemeshow")
  print(  completeModel@devcomp$cmp['dev'] /  baselineModel@devcomp$cmp['dev'] )
  print("Hosmer and Lemeshow")
  print(  (baselineModel@devcomp$cmp['dev'] - completeModel@devcomp$cmp['dev']) /  baselineModel@devcomp$cmp['dev'] )
  print("Cox and Snells")
  cs <- 1 - exp( (completeModel@devcomp$cmp['dev'] - baselineModel@devcomp$cmp['dev']) / nrow(completeModel@frame)  )
  print(  cs  )
  print("Nagelkerke")
  print(  cs / ( 1 - exp(- baselineModel@devcomp$cmp['dev'] / nrow(completeModel@frame) )  )  )

}

#Testing if multilevel makes sense: intercept and intercept with multilevel
agrad_intercept_ns <- create_model_only_int(agrad_nscaled)
agrad_intercept_user_ns <- create_model_only_int_random(agrad_nscaled)
summary(agrad_intercept_ns)
summary(agrad_intercept_user_ns)
logLik(agrad_intercept_ns)*-2 
logLik(agrad_intercept_user_ns)*-2

agrad_random_user_nscaled <- create_random_model_w_interact(agrad_nscaled, "")
summary(agrad_random_user_nscaled)

#Scaled
agrad_intercept <- create_model_only_int(agrad_scaled)
agrad_intercept_user <- create_model_only_int_random(agrad_scaled)

summary(agrad_intercept)
summary(agrad_intercept_user)

logLik(agrad_intercept)*-2 
logLik(agrad_intercept_user)*-2

agrad_random_user <- create_random_model_w_interact(agrad_scaled, "")
summary(agrad_random_user)
fit_text <- unclass(agrad_random_user)#Removing attributes to show
attributes(fit_text)
cc <- confint(agrad_random_user, parm="beta_", level = 0.95, method="boot", nsim=1, parallel="multicore", ncpus=2)
ctab <- cbind(est=fixef(agrad_random_user), cc)
rtab <- exp(ctab)
print(rtab, digits=3)
computePseudoR2(baselineModel = agrad_intercept_user, completeModel = agrad_random_user)

relagrad <- with(agrad_random_user@optinfo$derivs,solve(Hessian,gradient))#Testing convergence
max(abs(relagrad))

agrad_random_user_bob <- create_random_model_w_interact(agrad_scaled, "bobyqa")#Testing difference optimizers
summary(agrad_random_user)
agrad_random_user_nelder <- create_random_model_w_interact(agrad_scaled, "Nelder_Mead")
summary(agrad_random_user)

#95 CI intercept with variance/std of userID
-0.115328 + 0.1451/sqrt(15743)*qnorm(1-(0.05/2))#Num of observations
-0.115328 - 0.1451/sqrt(15743)*qnorm(1-(0.05/2))

-0.115328 + 0.1451/sqrt(282)*qnorm(1-(0.05/2))#Num of userID groups
-0.115328 - 0.1451/sqrt(282)*qnorm(1-(0.05/2))

#Safety
seg_intercept_ns <- create_model_only_int(seg_nscaled)#Not scaled
seg_intercept_user_ns <- create_model_only_int_random(seg_nscaled)
summary(seg_intercept_ns)
summary(seg_intercept_user_ns)
logLik(seg_intercept_ns)*-2 
logLik(seg_intercept_user_ns)*-2

seg_random_user_notscaled <- create_random_model_w_interact(seg_nscaled, "")
summary(seg_random_user_notscaled)

seg_intercept <- create_model_only_int(seg_scaled)#Scaled
seg_intercept_user <- create_model_only_int_random(seg_scaled)
summary(seg_intercept)
summary(seg_intercept_user)
logLik(seg_intercept)*-2 
logLik(seg_intercept_user)*-2

seg_random_user <- create_random_model_w_interact(seg_scaled, "")
summary(seg_random_user)
cc <- confint(seg_random_user, parm="beta_", level = 0.95, method="boot", nsim=1, parallel="multicore", ncpus=2)
ctab <- cbind(est=fixef(seg_random_user), cc)
rtab <- exp(ctab)
print(rtab, digits=3)
relseg <- with(seg_random_user@optinfo$derivs,solve(Hessian,gradient))#Testing convergence: https://github.com/lme4/lme4/issues/120
max(abs(relseg))
computePseudoR2(baselineModel = seg_intercept_user, completeModel = seg_random_user)

seg_random_user_bob <- create_random_model_w_interact(seg_scaled, "bobyqa")
summary(seg_random_user)
seg_random_user_nelder <- create_random_model_w_interact(seg_scaled, "Nelder_Mead")
summary(seg_random_user)

#95 CI intercept with variance/std of userID
-0.1196924 + 0.1547/sqrt(15127)*qnorm(1-(0.05/2))#Num of observations
-0.1196924 - 0.1547/sqrt(15127)*qnorm(1-(0.05/2))

-0.1196924 + 0.1547/sqrt(279)*qnorm(1-(0.05/2))#Num of userID groups
-0.1196924 - 0.1547/sqrt(279)*qnorm(1-(0.05/2))
```

# Logit analysis without random effects
```{r model.safe}
#Creating only one level models, without random effects
mostpleasant_model <- create_model_w_interact(agrad_nscaled)
summary(mostpleasant_model)
vif(mostpleasant_model)
#About McFadden R2: http://stats.stackexchange.com/questions/82105/mcfaddens-pseudo-r2-interpretation/99615
pR2(mostpleasant_model)
#anova(mostpleasant_model, test="Chisq")

mostpleasant_model_scaled <- create_model_w_interact(agrad_scaled)
summary(mostpleasant_model_scaled)
vif(mostpleasant_model_scaled)
pR2(mostpleasant_model_scaled)

mostpleasant_model_wo_profile <- create_model_wo_profile(agrad_scaled)
summary(mostpleasant_model_wo_profile)
vif(mostpleasant_model_wo_profile)

#About using divide by 4 rule to interpret betas: http://www.stefan-evert.de/SIGIL/sigil_R/materials/regression3.slides.pdf ; http://www.gettinggeneticsdone.com/2010/12/using-divide-by-4-rule-to-interpret.html ; http://andrewgelman.com/2007/05/18/multilevel_logi/
coefs_ag = tidy(mostpleasant_model, conf.int = TRUE, exponentiate = TRUE) 
coefs_ag %>% 
  mutate_at(vars(-1), prettyNum, digits = 3) %>%
  datatable()
library(xtable)
xtable(coefs_ag)

coefs_ag_scaled = tidy(mostpleasant_model_scaled, conf.int = TRUE, exponentiate = TRUE) 
coefs_ag_scaled %>% 
  mutate_at(vars(-1), prettyNum, digits = 3) %>%
  datatable()

#Safety
safer_model <- create_model_w_interact(seg_nscaled)
summary(safer_model)
#anova(safer_model, test="Chisq")
vif(safer_model)
pR2(safer_model)

safer_model_scaled <- create_model_w_interact(seg_scaled)
summary(safer_model_scaled)
vif(safer_model_scaled)
pR2(safer_model_scaled)

safer_model_wo_profile <- create_model_wo_profile(seg_scaled)
summary(safer_model_wo_profile)
vif(safer_model_wo_profile)

coefs_seg = tidy(safer_model, conf.int = TRUE, exponentiate = TRUE) 
coefs_seg %>% 
  mutate_at(vars(-1), prettyNum, digits = 3) %>% 
  datatable()

coefs_seg_scaled = tidy(safer_model_scaled, conf.int = TRUE, exponentiate = TRUE) 
coefs_seg_scaled %>% 
  mutate_at(vars(-1), prettyNum, digits = 3) %>% 
  datatable()
```

#Nazareno graph per group
```{r visualize_models}
library(modelr) # devtools::install_github("hadley/modelr")

m = agrad %>%
  data_grid(agrad, 
            .model = mostpleasant_model)

mm = augment(mostpleasant_model,
             newdata = m,
             type.predict = "response")

ggplot(mm, aes(x = d_lands)) + 
  geom_hex(aes(y = .fitted)) +  
  geom_count(aes(y = as.numeric(as.character(choice))), alpha = .1) + 
  facet_grid(gender ~ inc_cat + age_cat) 

```

#Analysing different thresholds for leave user out predicting as 1 or 0 using logit models
```{r visualize_models}
#Analysing leave user out results
source("analisaICPorFoto.R")

computeICForArrayOfValues <- function(files) {
  for (file in files){
    data <- read.table(file, header=TRUE)
    distance <- ic(filter(data, x != "NA")$x)
    meanValue <- mean(data$x, na.rm = TRUE)
    print(paste(file, meanValue, (meanValue - distance), (meanValue + distance), sep = "\t"))
  }
}

files <- c('logit/accuraciesA.dat', 'logit/accuraciesS.dat', 'logit/accuraciesA_WOProfile.dat', 'logit/accuraciesS_WOProfile.dat')
files <- c('logit/accuraciesA0.5.dat', 'logit/accuraciesA0.6.dat', 'logit/accuraciesA0.7.dat')
computeICForArrayOfValues(files)

files <- c('logit/precisionA0.5.dat', 'logit/precisionA0.6.dat', 'logit/precisionA0.7.dat')
computeICForArrayOfValues(files)

files <- c('logit/recallA0.5.dat', 'logit/recallA0.6.dat', 'logit/recallA0.7.dat')
computeICForArrayOfValues(files)

files <- c('logit/precisionA.dat', 'logit/precisionS.dat', 'logit/precisionA_WOProfile.dat', 'logit/precisionS_WOProfile.dat')
computeICForArrayOfValues(files)

files <- c('logit/recallA.dat', 'logit/recallS.dat', 'logit/recallA_WOProfile.dat', 'logit/recallS_WOProfile.dat')
computeICForArrayOfValues(files)
```

#Analysing pvalues, coefficients for leave user out logit models. Analysing  classifiers with/without profile
```{r visualize_models}
filesCoef <- c('coefficientsA.dat', 'coefficientsS.dat')
filesPval <- c('pvaluesA.dat', 'pvaluesS.dat')
for (index in 1:2){
  coefData <- read.table(filesCoef[index], skip=1)
  pvalData <- read.table(filesPval[index], skip=1)
  
  #Values in exp()
  distancesCoef <- apply(coefData[, c(2:ncol(coefData))], 1, ic)
  meanCoef <- apply(coefData[, c(2:ncol(coefData))], 1, mean)
  coefData$mean <- meanCoef
  coefData$low <- meanCoef - distancesCoef
  coefData$high <- meanCoef + distancesCoef

  distancesPval <- apply(pvalData[, c(2:ncol(pvalData))], 1, ic)
  meanPval <- apply(pvalData[, c(2:ncol(pvalData))], 1, mean)
  pvalData$mean <- meanPval
  pvalData$low <- meanPval - distancesPval
  pvalData$high <- meanPval + distancesPval
  
  print(paste(filesCoef[index], coefData$V1, coefData$mean, coefData$low, coefData$high, pvalData$mean, pvalData$low, pvalData$high, sep = "\t"), quote=FALSE)
}

#Extra Trees analysis
calcICFromMeanAndSD <- function(notprof_mean, notprof_sd, prof_mean, prof_sd){
    distance <- (notprof_sd/sqrt(282)*qnorm(1-(0.05/2)))
    print(paste("not profile", notprof_mean, notprof_mean - distance, notprof_mean + distance))
    distance <- (agrad_prof_sd/sqrt(282)*qnorm(1-(0.05/2)))
    print(paste("profile", prof_mean, prof_mean - distance, prof_mean + distance))
}

agrad_notprof_mean <- 0.54611294
agrad_notprof_sd <- 0.20911696
agrad_prof_mean <- 0.59370316
agrad_prof_sd <- 0.22663894
calcICFromMeanAndSD(agrad_notprof_mean, agrad_notprof_sd, agrad_prof_mean, agrad_prof_sd)

seg_notprof_mean <- 0.52667729
seg_notprof_sd <- 0.21595407
seg_prof_mean <- 0.57516886
seg_prof_sd <- 0.20420293
calcICFromMeanAndSD(seg_notprof_mean, seg_notprof_sd, seg_prof_mean, seg_prof_sd)

#Error bars for classifiers
pleas_acc_fbeta <- data.frame(lower=c(0.62, 0.56, 0.58, 0.52, 0.49), upper=c(0.66, 0.62, 0.61, 0.57, 0.51), class=c("Extra Trees with respondent profile", "Extra Trees with respondent profile", "Extra Trees without respondent profile", "Extra Trees without respondent profile", "Random Classifier Acc."), fill=c(1,2,3,4,5), group=c("Accuracy", "F-beta", "Accuracy", "F-beta", "Accuracy"))
pleas_acc_fbeta$meanVal <- (pleas_acc_fbeta$upper - pleas_acc_fbeta$lower)/2 + pleas_acc_fbeta$lower

h = 13.3
w = 19
pdf("images/pleas_acc.pdf", width = w, height = h)
ggplot(pleas_acc_fbeta, aes(x=fill, y=meanVal, fill=class)) + 
    geom_bar(position=position_dodge(), stat="identity") +
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.2, position=position_dodge(.9)) + xlab("") + ylab("") + theme( axis.ticks.x=element_blank(), strip.text.y = element_text(size=40), legend.text = element_text(size=40), legend.title = element_text(size=40)) + guides(fill=guide_legend(title="Classifier")) + theme_bw() + facet_grid(.~group) 
dev.off()

saf_acc_fbeta <- data.frame(lower=c(0.61, 0.54, 0.57, 0.50, 0.50), upper=c(0.65, 0.60, 0.60, 0.55, 0.54), class=c("Extra Trees with respondent profile", "Extra Trees with respondent profile", "Extra Trees without respondent profile", "Extra Trees without respondent profile", "Random Classifier Acc."), fill=c(1,2,3,4,5), group=c("Accuracy", "F-beta", "Accuracy", "F-beta", "Accuracy"))
saf_acc_fbeta$meanVal <- (saf_acc_fbeta$upper - saf_acc_fbeta$lower)/2 + saf_acc_fbeta$lower

h = 13.3
w = 19
pdf("images/saf_acc.pdf", width = w, height = h)
ggplot(saf_acc_fbeta, aes(x=fill, y=meanVal, fill=class)) + 
    geom_bar(position=position_dodge(), stat="identity") +
    geom_errorbar(aes(ymin=lower, ymax=upper), width=.2, position=position_dodge(.9)) + xlab("") + ylab("") + theme( axis.ticks.x=element_blank(), strip.text.y = element_text(size=40), legend.text = element_text(size=40), legend.title = element_text(size=40)) + guides(fill=guide_legend(title="Classifier")) + theme_bw() + facet_grid(.~group) 
dev.off()


```

#Sankey diagrams for importances of urban qualities
```{r visualize_models}
#Sankey network graph!
#Online tool: http://sankey.csaladen.es/
library(networkD3)

#Exemplo Internet!
URL <- paste0(
        "https://cdn.rawgit.com/christophergandrud/networkD3/",
        "master/JSONdata/energy.json")
Energy <- jsonlite::fromJSON(URL)
# Plot
sankeyNetwork(Links = Energy$links, Nodes = Energy$nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             units = "TWh", fontSize = 12, nodeWidth = 30)

#Pleasantness - Not normalized
featuresRelativeImportances = list()
featuresRelativeImportances['maintenance'] = 13.8+2.7+2.1
featuresRelativeImportances['street_width'] = 0.27+0.27
featuresRelativeImportances['trees'] = 1.085+1.085
featuresRelativeImportances['people'] = 1.35
featuresRelativeImportances['parked_cars'] = 0.27
featuresRelativeImportances['cyclist'] = 2.71
featuresRelativeImportances['b_id'] = 0.54
featuresRelativeImportances['moving_cars'] = 2.17

urbanQualities = data.frame(name=c("Maintenance", "Tidiness - 18.7%", "Street width", "Trees", "People", "Moving cars", "Cyclist", "Human Scale - 8.9%", "Parked cars", "Trees", "Cyclists", "People", "Moving cars", "Complexity - 8.6%", "Street width", "Trees", "Enclosure - 2.7%", "Buildings Identifiers", "People", "Imageability - 1.8%", "People", "Coherence - 1.3%", "Street width", "Linkage - 0.54%", "Buildings with identifiers", "Legibility - 0.54%", "Pleasantness"))
 mylist<-list(dimension=urbanQualities, links=data.frame(source=c(0, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 17, 18, 20, 22, 24, 1, 7, 13, 16, 19, 21, 23, 25), target=c(1, 7, 7, 7, 7, 7, 13, 13, 13, 13, 13, 16, 16, 19, 19, 21, 23, 25, 26, 26, 26, 26, 26, 26, 26, 26), value=c(featuresRelativeImportances$maintenance, featuresRelativeImportances$street_width, featuresRelativeImportances$trees, featuresRelativeImportances$people, featuresRelativeImportances$moving_cars, featuresRelativeImportances$cyclist, featuresRelativeImportances$parked_cars, featuresRelativeImportances$trees, featuresRelativeImportances$cyclist , featuresRelativeImportances$people, featuresRelativeImportances$moving_cars, featuresRelativeImportances$street_width, featuresRelativeImportances$trees, featuresRelativeImportances$b_id, featuresRelativeImportances$people, featuresRelativeImportances$people, featuresRelativeImportances$street_width, featuresRelativeImportances$b_id, 18.7, 8.9, 8.6, 2.7, 1.8, 1.3, 0.54, 0.54  )) )

sankeyNetwork(Links = mylist$links, Nodes = mylist$dimension, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             units = "%", fontSize = 16, nodeWidth = 10, width=533, height=390)#Save with 600, 390

#Pleasantness - Normalized
featuresRelativeImportances = list()
featuresRelativeImportances['maintenance'] = 11.02 + 2.28 + 1.92
featuresRelativeImportances['street_width'] = 2.5 + 2.4 
featuresRelativeImportances['trees'] = 2.86 + 3.58
featuresRelativeImportances['people'] = 4.29
featuresRelativeImportances['parked_cars'] = 2.08
featuresRelativeImportances['cyclist'] = 1.88
featuresRelativeImportances['b_id'] = 2.09
featuresRelativeImportances['moving_cars'] = 3.86
urbanQualities = data.frame(name=c("Street width", "Trees", "People", "Moving cars", "Cyclist", "Human Scale - 21.4%", "Parked cars", "Trees", "Cyclists", "People", "Moving cars", "Complexity - 18.5%", "Maintenance", "Tidiness - 15.2%", "Street width", "Trees", "Enclosure - 11.3%", "Buildings Identifiers", "People", "Imageability - 6.3%", "Street width", "Linkage - 4.9%", "People", "Coherence - 4.2%", "Buildings with identifiers", "Legibility - 2%", "Pleasantness"))
 mylist<-list(dimension=urbanQualities, links=data.frame(source=c(0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 14, 15, 17, 18, 20, 22, 24, 5, 11, 13, 16, 19, 21, 23, 25), target=c(5, 5, 5, 5, 5, 11, 11, 11, 11, 11, 13, 16, 16, 19, 19, 21, 23, 25, 26, 26, 26, 26, 26, 26, 26, 26), value=c(featuresRelativeImportances$street_width, featuresRelativeImportances$trees, featuresRelativeImportances$people, featuresRelativeImportances$moving_cars, featuresRelativeImportances$cyclist, featuresRelativeImportances$parked_cars, featuresRelativeImportances$trees, featuresRelativeImportances$cyclist, featuresRelativeImportances$people, featuresRelativeImportances$moving_cars, featuresRelativeImportances$maintenance, featuresRelativeImportances$street_width, featuresRelativeImportances$trees, featuresRelativeImportances$b_id, featuresRelativeImportances$people, featuresRelativeImportances$street_width, featuresRelativeImportances$people, featuresRelativeImportances$b_id, 21.4, 18.5, 15.2, 11.3, 6.38, 4.91, 4.2, 2.09)) )

sankeyNetwork(Links = mylist$links, Nodes = mylist$dimension, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             units = "%", fontSize = 16, nodeWidth = 10, width=533, height=390)#Save with 600, 390)

#Safety - Not normalized
featuresRelativeImportances = list()
featuresRelativeImportances['moving_cars'] = 5.41+1.7+2.27
featuresRelativeImportances['parked_cars'] = 0.85
featuresRelativeImportances['trees'] = 1.13+0.85
featuresRelativeImportances['maintenance'] = 1.13+3.41+3.13
featuresRelativeImportances['people'] = 1.42+1.42
featuresRelativeImportances['street_width'] = 0.28
featuresRelativeImportances['build'] = 1.99+1.42

urbanQualities = data.frame(name=c("Moving cars", "Parked cars", "Trees", "People", "Buildings", "Complexity - 18.5%", "Moving cars", "Trees", "People", "Street width", "Human Scale - 14.5%", "Moving cars", "Street width", "Linkage - 9.6%", "Maintenance", "Tidiness - 7.6%", "People", "Imageability - 2.84%", "People", "Coherence - 2.84%", "Trees", "Street width", "Enclosure - 2.27%", "Safety"))
 mylist<-list(dimension=urbanQualities, links=data.frame(source=c(0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 18, 20, 21, 5, 10, 13, 15, 17, 19, 22), target=c(5, 5, 5, 5, 5, 10, 10, 10, 10, 13, 13, 15, 17, 19, 22, 22, 23, 23, 23, 23, 23, 23, 23), value=c(featuresRelativeImportances$moving_cars, featuresRelativeImportances$parked_cars, featuresRelativeImportances$trees, featuresRelativeImportances$people, featuresRelativeImportances$build, featuresRelativeImportances$moving_cars, featuresRelativeImportances$trees, featuresRelativeImportances$people, featuresRelativeImportances$street_width, featuresRelativeImportances$moving_cars, featuresRelativeImportances$street_width, featuresRelativeImportances$maintenance, featuresRelativeImportances$people, featuresRelativeImportances$people, featuresRelativeImportances$trees, featuresRelativeImportances$street_width, 18.5, 14.5, 9.6, 7.6, 2.84, 2.84, 2.27  )) )


sankeyNetwork(Links = mylist$links, Nodes = mylist$dimension, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             units = "%", fontSize = 16, nodeWidth = 10, width=533, height=390)#Save with 600, 390

#Safety - scaled
featuresRelativeImportances = list()
featuresRelativeImportances['moving_cars'] = 7.9 + 2.46 + 3.26
featuresRelativeImportances['parked_cars'] = 3.58
featuresRelativeImportances['trees'] = 2.78 + 1.88
featuresRelativeImportances['maintenance'] = 7.5 + 2.44 + 2.2
featuresRelativeImportances['people'] = 3.73 + 3.39
featuresRelativeImportances['street_width'] = 3.54
featuresRelativeImportances['build'] = 3.76 + 2.73

urbanQualities = data.frame(name=c("Moving cars", "Parked cars", "Trees", "People", "Buildings", "Complexity - 35.5%", "Moving cars", "Trees", "People", "Street width", "Human Scale - 29%", "Moving cars", "Street width", "Linkage - 17.2%", "Maintenance", "Tidiness - 12.2%", "Trees", "Street width", "Enclosure - 8.2%", "People", "Imageability - 7.1%", "People", "Coherence - 7.1%", "Safety"))
 mylist<-list(dimension=urbanQualities, links=data.frame(source=c(0, 1, 2, 3, 4, 6, 7, 8, 9, 11, 12, 14, 16, 17, 19, 21, 5, 10, 13, 15, 18, 20, 22), target=c(5, 5, 5, 5, 5, 10, 10, 10, 10, 13, 13, 15, 18, 18, 20, 22, 23, 23, 23, 23, 23, 23, 23), value=c(featuresRelativeImportances$moving_cars, featuresRelativeImportances$parked_cars, featuresRelativeImportances$trees, featuresRelativeImportances$people, featuresRelativeImportances$build, featuresRelativeImportances$moving_cars, featuresRelativeImportances$trees, featuresRelativeImportances$people, featuresRelativeImportances$street_width, featuresRelativeImportances$moving_cars, featuresRelativeImportances$street_width, featuresRelativeImportances$maintenance, featuresRelativeImportances$trees, featuresRelativeImportances$street_width, featuresRelativeImportances$people, featuresRelativeImportances$people, 35.5, 29, 17.2, 12.2, 8.2, 7.1, 7.1)) )

sankeyNetwork(Links = mylist$links, Nodes = mylist$dimension, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             units = "%", fontSize = 16, nodeWidth = 10, width=533, height=390)

#http://sankey.csaladen.es/


#Flow examples - All Urban Qualities
plot.new()
par(mar=c(0,0,0,0)+.1)
plot.window(xlim=c(0,3), ylim=c(0,9))
xspline( c(1,1.25,1.75,2), c(9,9,4,4), s=1, lwd=32.8/4.5, border="#0000ff88", lend=1)
xspline( c(1,1.25,1.75,2), c(8,8,4,4), s=1, lwd=32.8/4.5, border="#0000ff88", lend=1)
xspline( c(1,1.25,1.75,2), c(7,7,4,4), s=1, lwd=32.8/4.5, border="#0000ff88", lend=1)
xspline( c(1,1.25,1.75,2), c(6,6,4,4), s=1, lwd=19.7/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(5,5,4,4), s=1, lwd=16.5/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(4,4,4,4), s=1, lwd=13.8/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(3,3,4,4), s=1, lwd= 7.9/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(2,2,4,4), s=1, lwd= 4.8/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(1,1,4,4), s=1, lwd= 4.5/4.5, border="#0000ff88", lend=1 )

#text( rep(0.75, 7), 7:1, LETTERS[1:7] )
text( rep(0.6, 9), 9:1, c("IMAGEABILITY", "ENCLOSURE", "HUMAN SCALE", "TRANSPARENCY", "TIDINESS", "COMPLEXITY", "COHERENCE", "LEGIBILITY", "LINKAGE") )
text( 0.6, 7.6, c("Trees"),  cex=0.9)#Enclosure
text( c(0.3, 0.8), 6.6, c("Trees", "Moving cars"),  cex=0.9)#Human Scale
text( 0.6, 4.6, c("Landscape"),  cex=0.9)#Tidiness
text( c(0.3, 0.3, 0.8, 0.8), c(3.75, 3.3, 3.75, 3.3), c("Trees", "Moving cars", "Parked cars", "Buildings"),  cex=0.9)#Complexity
text( 0.6, 0.6, c("Moving cars"),  cex=0.9)#Linkage
text( 2.25, 4, 'Pleasantness')

#Flow examples - Pleasantness!
w = 12
h = 7
pdf("images/flow_agrad.pdf", width = w, height = h)

plot.new()
par(mar=c(0,0,0,0)+.1)
plot.window(xlim=c(0,3), ylim=c(0,8))
xspline( c(1,1.25,1.75,2), c(8,8,4,4), s=1, lwd=32.8/4.5, border="#0000ff88", lend=1)
xspline( c(1,1.25,1.75,2), c(7,7,4,4), s=1, lwd=32.8/4.5, border="#0000ff88", lend=1)
xspline( c(1,1.25,1.75,2), c(6,6,4,4), s=1, lwd=19.7/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(5,5,4,4), s=1, lwd=16.5/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(4,4,4,4), s=1, lwd=13.8/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(3,3,4,4), s=1, lwd= 7.9/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(2,2,4,4), s=1, lwd= 4.8/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(1,1,4,4), s=1, lwd= 4.5/4.5, border="#0000ff88", lend=1 )

#text( rep(0.75, 7), 7:1, LETTERS[1:7] )
text( rep(0.7, 8), 8:1, c("HUMAN SCALE 21%", "COMPLEXITY 18%", "TIDINESS 15%", "ENCLOSURE 11%", "IMAGEABILITY 6%",  "LINKAGE 4.8%", "COHERENCE 4.2%",  "LEGIBILITY 2%") , cex=1.4)
text( c(0.4, 0.4, 0.9, 0.9), c(7.7, 7.3, 7.7, 7.3), c("Street width(-)", "Trees(+)", "People(+)", "Moving cars(+)"),  cex=1.4)#Human Scale
text( c(0.2, 0.55, 0.2, 0.9, 0.9), c(6.7, 6.6, 6.3, 6.7, 6.3), c("Trees(+)", "People(+)", "Parked cars(+)", "Ciclysts(+)", "Moving cars(+)"),  cex=1.4)#Complexity
text( 0.7, 5.6, c("Landscape(+)"),  cex=1.4)#Tidiness
text( c(0.4, 0.9), 4.6, c("Trees(+)", "Street width(-)"),  cex=1.4)#Enclosure
text( c(0.4, 0.9), 3.6, c("Buildings ident(+)", "People(+)"),  cex=1.4)#Imageability
text( c(0.4, 0.9), 2.6, c("Street width(?)", "Moving cars(?)"),  cex=1.4)#Linkage
text( 0.7, 1.6, c("People(+)"),  cex=1.4)#Coherence
text( 0.7, 0.6, c("Buildings ident(+)"),  cex=1.4)#Legibility

text( 2.25, 4, 'Pleasantness', cex=1.4)

dev.off()

#Flow examples - Safety!
w = 12
h = 7
pdf("images/flow_seg.pdf", width = w, height = h)

plot.new()
par(mar=c(0,0,0,0)+.1)
plot.window(xlim=c(0,3), ylim=c(0,8))
xspline( c(1,1.25,1.75,2), c(7,7,4,4), s=1, lwd=32.8/4.5, border="#0000ff88", lend=1)
xspline( c(1,1.25,1.75,2), c(6,6,4,4), s=1, lwd=19.7/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(5,5,4,4), s=1, lwd=16.5/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(4,4,4,4), s=1, lwd=13.8/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(3,3,4,4), s=1, lwd= 7.9/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(2,2,4,4), s=1, lwd= 4.8/4.5, border="#0000ff88", lend=1 )
xspline( c(1,1.25,1.75,2), c(1,1,4,4), s=1, lwd= 4.5/4.5, border="#0000ff88", lend=1 )

#text( rep(0.75, 7), 7:1, LETTERS[1:7] )
text( rep(0.7, 7), 7:1, c("COMPLEXITY 36.9%", "HUMAN SCALE 30%", "LINKAGE 17.9%", "TIDINESS 12.6%", "ENCLOSURE 8.5%", "IMAGEABILITY 7.4%",  "COHERENCE 7.4%" ) , cex=1.4)
text( c(0.2, 0.6, 0.4, 0.9, 0.9), c(6.7, 6.6, 6.3, 6.7, 6.3), c("Moving cars(+)", "Trees(+)", "Parked cars(+)", "People(+)", "Buildings(+)"),  cex=1.4)#Complexity
text( c(0.4, 0.4, 0.9, 0.9), c(5.7, 5.3, 5.7, 5.3), c("Moving cars(+)", "Trees(+)", "People(+)", "Street width(-)"),  cex=1.4)#Human Scale
text( c(0.4, 0.9), 4.6, c("Moving cars(?)", "Street width(?)"),  cex=1.4)#Linkage
text( 0.7, 3.6, c("Landscape(+)"),  cex=1.4)#Tidiness
text( c(0.4, 0.9), 2.6, c("Trees(+)", "Street width(-)"),  cex=1.4)#Enclosure
text( 0.7, 1.6, c("People(+)"),  cex=1.4)#Imageability
text( 0.7, 0.6, c("People(+)"),  cex=1.4)#Coherence

text( 2.25, 4, 'Safety', cex=1.4)
dev.off()
```
